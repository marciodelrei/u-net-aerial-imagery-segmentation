{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from enum import Enum\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from patchify import patchify\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.layers import Rescaling\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn as sk\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "# print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# image preprocessing\n",
    "\n",
    "def load_images_and_patchify(directory_path, patch_size):\n",
    "    \"\"\"\n",
    "    :param patch_size: image patchify square size\n",
    "    :param directory_path: path to root directory containing training and test images\n",
    "    :return: list of images from directory\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize empty list for images\n",
    "    instances = []\n",
    "\n",
    "    # iterate through files in directory\n",
    "    for file_number, filepath in tqdm(enumerate(os.listdir(directory_path))):\n",
    "        extension = filepath.split(\".\")[-1]\n",
    "        if extension == \"jpg\" or extension == \"png\":\n",
    "\n",
    "            # current image path\n",
    "            img_path = rf\"{directory_path}/{filepath}\"\n",
    "\n",
    "            # Reads image as BGR\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            # convert image to RBG\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            size_x = (image.shape[1] // patch_size) * patch_size  # width to the nearest size divisible by patch size\n",
    "            size_y = (image.shape[0] // patch_size) * patch_size  # height to the nearest size divisible by patch size\n",
    "\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            # Crop original image to size divisible by patch size from top left corner\n",
    "            image = np.array(image.crop((0, 0, size_x, size_y)))\n",
    "\n",
    "            # Extract patches from each image, step=patch_size means no overlap\n",
    "            patch_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "            # iterate over vertical patch axis\n",
    "            for j in range(patch_img.shape[0]):\n",
    "                # iterate over horizontal patch axis\n",
    "                for k in range(patch_img.shape[1]):\n",
    "                    # patches are located like a grid. use (j, k) indices to extract single patched image\n",
    "                    single_patch_img = patch_img[j, k]\n",
    "\n",
    "                    # Drop extra dimension from patchify\n",
    "                    instances.append(np.squeeze(single_patch_img))\n",
    "\n",
    "    return instances\n",
    "\n",
    "\n",
    "def reshape_images(instances):\n",
    "    \"\"\"\n",
    "    :param instances: list of images\n",
    "    :return: reshaped images\n",
    "    \"\"\"\n",
    "    for j in range(len(instances)):\n",
    "        instances[j] = instances[j].reshape(-1, 1)\n",
    "    return instances\n",
    "\n",
    "\n",
    "def get_minimum_image_size(instances):\n",
    "    \"\"\"\n",
    "    :param instances: list of images\n",
    "    :return: min and max dimensions out of all images\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize minimum values to infinity\n",
    "    min_x = math.inf\n",
    "    min_y = math.inf\n",
    "\n",
    "    # loop through each instance\n",
    "    for image in instances:\n",
    "        # check min x (rows)\n",
    "        min_x = image.shape[0] if image.shape[0] < min_x else min_x\n",
    "\n",
    "        # check min y (columns)\n",
    "        min_y = image.shape[1] if image.shape[1] < min_y else min_y\n",
    "\n",
    "    return min_x, min_y\n",
    "\n",
    "\n",
    "def display_images(instances, rows=2, titles=None):\n",
    "    \"\"\"\n",
    "    :param instances:  list of images\n",
    "    :param rows: number of rows in subplot\n",
    "    :param titles: subplot titles\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(instances)\n",
    "    cols = n // rows if (n / rows) % rows == 0 else (n // rows) + 1\n",
    "\n",
    "    # iterate through images and display subplots\n",
    "    for j, image in enumerate(instances):\n",
    "        plt.subplot(rows, cols, j + 1)\n",
    "        plt.title('') if titles is None else plt.title(titles[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# prepare training data input images\n",
    "\n",
    "def get_training_data(root_directory):\n",
    "    # initialise lists\n",
    "    image_dataset, mask_dataset = [], []\n",
    "\n",
    "    # define image patch size\n",
    "    patch_size = 160\n",
    "\n",
    "    # walk through root directory\n",
    "    for path, directories, files in os.walk(root_directory):\n",
    "        for subdirectory in directories:\n",
    "\n",
    "            # extract training input images and patchify\n",
    "            if subdirectory == \"images\":\n",
    "                image_dataset.extend(\n",
    "                    load_images_and_patchify(os.path.join(path, subdirectory), patch_size=patch_size))\n",
    "\n",
    "            # extract training label masks and patchify\n",
    "            elif subdirectory == \"masks\":\n",
    "                mask_dataset.extend(\n",
    "                    load_images_and_patchify(os.path.join(path, subdirectory), patch_size=patch_size))\n",
    "\n",
    "    # return input images and masks\n",
    "    return np.array(image_dataset), np.array(mask_dataset)\n",
    "\n",
    "\n",
    "def create_binary_segmentation_problem(image_dataset, mask_dataset):\n",
    "    # change problem to binary segmentation problem\n",
    "    x_reduced, y_reduced = [], []\n",
    "\n",
    "    # iterate over masks\n",
    "    for j, mask in tqdm(enumerate(mask_dataset)):\n",
    "\n",
    "        # get image shape\n",
    "        _img_height, _img_width, _img_channels = mask.shape\n",
    "\n",
    "        # create binary image (zeros)\n",
    "        binary_image = np.zeros((_img_height, _img_width, 1)).astype(int)\n",
    "\n",
    "        # iterate over each pixel in mask\n",
    "        for row in range(_img_height):\n",
    "            for col in range(_img_width):\n",
    "                # get image channel across axis=3\n",
    "                rgb = mask[row, col, :]\n",
    "\n",
    "                # building hex: #3C1098 = RGB(60, 16, 152) or BGR(152, 16, 60)\n",
    "                binary_image[row, col] = 1 if rgb[0] == 60 and rgb[1] == 16 and rgb[2] == 152 else 0\n",
    "\n",
    "        # only keep images with a high percentage of building coverage\n",
    "        if np.count_nonzero(binary_image == 1) > 0.15 * binary_image.size:\n",
    "            x_reduced.append(image_dataset[j])\n",
    "            y_reduced.append(binary_image)\n",
    "\n",
    "    # return binary image dataset\n",
    "    return np.array(x_reduced), np.array(y_reduced)\n",
    "\n",
    "\n",
    "# mask color codes\n",
    "# class MaskColorMap(Enum):\n",
    "#     Unlabelled = (155, 155, 155)\n",
    "#     Building = (60, 16, 152)\n",
    "#     Land = (132, 41, 246)\n",
    "#     Road = (110, 193, 228)\n",
    "#     Vegetation = (254, 221, 58)\n",
    "#     Water = (226, 169, 41)\n",
    "\n",
    "class MaskColorMap(Enum):\n",
    "    unlabeled = (0, 0, 0)\n",
    "    paved_area = (128, 64, 128)\n",
    "    dirt = (130, 76, 0)\n",
    "    grass = (0, 102, 0)\n",
    "    gravel = (112, 103, 87)\n",
    "    water = (28, 42, 168)\n",
    "    rocks = (48, 41, 30)\n",
    "    pool = (0, 50, 89)\n",
    "    vegetation = (107, 142, 35)\n",
    "    roof = (70, 70, 70)\n",
    "    wall = (102, 102, 156)\n",
    "    window = (254, 228, 12)\n",
    "    door = (254, 148, 12)\n",
    "    fence = (190, 153, 153)\n",
    "    fence_pole = (153, 153, 153)\n",
    "    person = (255, 22, 96)\n",
    "    dog = (102, 51, 0)\n",
    "    car = (9, 143, 150)\n",
    "    bicycle = (119, 11, 32)\n",
    "    tree = (51, 51, 0)\n",
    "    bald_tree = (190, 250, 190)\n",
    "    ar_marker = (112, 150, 146)\n",
    "    obstacle = (2, 135, 115)\n",
    "    conflicting = (255, 0, 0)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode_masks(masks, num_classes):\n",
    "    \"\"\"\n",
    "    :param masks: Y_train patched mask dataset\n",
    "    :param num_classes: number of classes\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # initialise list for integer encoded masks\n",
    "    integer_encoded_labels = []\n",
    "\n",
    "    # iterate over each mask\n",
    "    for mask in tqdm(masks):\n",
    "\n",
    "        # get image shape\n",
    "        _img_height, _img_width, _img_channels = mask.shape\n",
    "\n",
    "        # create new mask of zeros\n",
    "        encoded_image = np.zeros((_img_height, _img_width, 1)).astype(int)\n",
    "\n",
    "        for j, cls in enumerate(MaskColorMap):\n",
    "            encoded_image[np.all(mask == cls.value, axis=-1)] = j\n",
    "\n",
    "        # append encoded image\n",
    "        integer_encoded_labels.append(encoded_image)\n",
    "\n",
    "    # return one-hot encoded labels\n",
    "    return to_categorical(y=integer_encoded_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_now_formatted() -> str:\n",
    "    dt_now = str(datetime.datetime.now())\n",
    "    dt_now = dt_now.replace(\"-\",\"\")\n",
    "    dt_now = dt_now.replace(\" \",\"_\")\n",
    "    dt_now = dt_now.replace(\":\",\"\")\n",
    "    dt_now = dt_now.replace(\".\",\"\")\n",
    "    print(dt_now)\n",
    "    return dt_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# output directories\n",
    "\n",
    "# datetime for filename saving\n",
    "dt_now = get_dt_now_formatted()\n",
    "current_dir = os.getcwd()\n",
    "models_dir = \"models\"\n",
    "logs_dir = \"logs\"\n",
    "file_name_save = f\"final_aerial_segmentation_{dt_now}\"\n",
    "model_img_save_path = os.path.join(current_dir, models_dir, f\"{file_name_save}.png\")\n",
    "model_save_path = os.path.join(current_dir, models_dir, f\"{file_name_save}.hdf5\")\n",
    "model_checkpoint_filepath = os.path.join(current_dir, models_dir, \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "csv_logger = os.path.join(current_dir, logs_dir, f\"aerial_segmentation_log_{dt_now}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# training metrics\n",
    "\n",
    "# Mean Intersection-Over-Union: iou = true_positives / (true_positives + false_positives + false_negatives)\n",
    "def iou_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2, 3])\n",
    "    union = K.sum(y_true, [1, 2, 3]) + K.sum(y_pred, [1, 2, 3]) - intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# jaccard similarity: the size of the intersection divided by the size of the union of two sets\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# get training data\n",
    "\n",
    "# number of classes in segmentation dataset\n",
    "n_classes = 6\n",
    "\n",
    "# dataset directory\n",
    "# data_dir = \"semantic_segmentation_dataset\"\n",
    "data_dir = \"semantic\"\n",
    "\n",
    "# create (X, Y) training data\n",
    "X, Y = get_training_data(root_directory=data_dir)\n",
    "\n",
    "# extract X_train shape parameters\n",
    "m, img_height, img_width, img_channels = X.shape\n",
    "print('number of patched image training data:', m)\n",
    "\n",
    "# display images from both training and test sets\n",
    "display_count = 6\n",
    "random_index = [np.random.randint(0, m) for _ in range(display_count)]\n",
    "sample_images = [x for z in zip(list(X[random_index]), list(Y[random_index])) for x in z]\n",
    "display_images(sample_images, rows=2)\n",
    "\n",
    "# convert RGB values to integer encoded labels for categorical_crossentropy\n",
    "Y = one_hot_encode_masks(Y, num_classes=n_classes)\n",
    "\n",
    "# split dataset into training and test groups\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# define U-Net model architecture\n",
    "\n",
    "def build_unet(img_shape):\n",
    "    # input layer shape is equal to patch image size\n",
    "    inputs = Input(shape=img_shape)\n",
    "\n",
    "    # rescale images from (0, 255) to (0, 1)\n",
    "    rescale = Rescaling(scale=1. / 255, input_shape=(img_height, img_width, img_channels))(inputs)\n",
    "    previous_block_activation = rescale  # Set aside residual\n",
    "\n",
    "    contraction = {}\n",
    "    # # Contraction path: Blocks 1 through 5 are identical apart from the feature depth\n",
    "    for f in [16, 32, 64, 128]:\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(\n",
    "            previous_block_activation)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        contraction[f'conv{f}'] = x\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        previous_block_activation = x\n",
    "\n",
    "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(\n",
    "        previous_block_activation)\n",
    "    c5 = Dropout(0.2)(c5)\n",
    "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    previous_block_activation = c5\n",
    "\n",
    "    # Expansive path: Second half of the network: upsampling inputs\n",
    "    for f in reversed([16, 32, 64, 128]):\n",
    "        x = Conv2DTranspose(f, (2, 2), strides=(2, 2), padding='same')(previous_block_activation)\n",
    "        x = concatenate([x, contraction[f'conv{f}']])\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        previous_block_activation = x\n",
    "\n",
    "    outputs = Conv2D(filters=n_classes, kernel_size=(1, 1), activation=\"softmax\")(previous_block_activation)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# build model\n",
    "model = build_unet(img_shape=(img_height, img_width, img_channels))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# add callbacks, compile model and fit training data\n",
    "\n",
    "# save best model with maximum validation accuracy\n",
    "checkpoint = ModelCheckpoint(model_checkpoint_filepath, monitor=\"val_accuracy\", verbose=1, save_best_only=True,\n",
    "                             mode=\"max\")\n",
    "\n",
    "# stop model training early if validation loss doesn't continue to decrease over 2 iterations\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=2, verbose=1, mode=\"min\")\n",
    "\n",
    "# log training console output to csv\n",
    "csv_logger = CSVLogger(csv_logger, separator=\";\", append=False)\n",
    "\n",
    "# create list of callbacks\n",
    "callbacks_list = [checkpoint, csv_logger]  # early_stopping\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", iou_coefficient, jaccard_index])\n",
    "\n",
    "# train and save model\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_data=(X_test, Y_test), callbacks=callbacks_list,\n",
    "          verbose=1)\n",
    "model.save(model_save_path)\n",
    "print(\"model saved:\", model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# load pre-trained model\n",
    "\n",
    "# model_dir = '/Users/andrewdavies/Code/tensorflow-projects/u-net-aerial-imagery-segmentation/models/'\n",
    "model_dir = 'models/'\n",
    "model_name = 'final_aerial_segmentation_20230507_192936400066.hdf5'\n",
    "\n",
    "# model = load_model(\n",
    "#     model_dir + model_name,\n",
    "#     custom_objects={'iou_coefficient': iou_coefficient, 'jaccard_index': jaccard_index}\n",
    "# )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Predict\n",
    "\n",
    "def rgb_encode_mask(mask):\n",
    "    # initialize rgb image with equal spatial resolution\n",
    "    rgb_encode_image = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    # iterate over MaskColorMap\n",
    "    for j, cls in enumerate(MaskColorMap):\n",
    "        # convert single integer channel to RGB channels\n",
    "        rgb_encode_image[(mask == j)] = np.array(cls.value) / 255.\n",
    "    return rgb_encode_image\n",
    "\n",
    "def predict_model_just_created(use_model: Model):\n",
    "    if use_model is None:\n",
    "        model_dir = 'models/'\n",
    "        model_name = 'final_aerial_segmentation_2022-11-09 22_37_27_640199.hdf5'\n",
    "        use_model = load_model(\n",
    "            model_dir + model_name,\n",
    "            custom_objects={'iou_coefficient': iou_coefficient, 'jaccard_index': jaccard_index})\n",
    "\n",
    "    for _ in range(20):\n",
    "        # choose random number from 0 to test set size\n",
    "        test_img_number = np.random.randint(0, len(X_test))\n",
    "\n",
    "        # extract test input image\n",
    "        test_img = X_test[test_img_number]\n",
    "\n",
    "        # ground truth test label converted from one-hot to integer encoding\n",
    "        ground_truth = np.argmax(Y_test[test_img_number], axis=-1)\n",
    "\n",
    "        # expand first dimension as U-Net requires (m, h, w, nc) input shape\n",
    "        test_img_input = np.expand_dims(test_img, 0)\n",
    "\n",
    "        # make prediction with model and remove extra dimension\n",
    "        # prediction = np.squeeze(model.predict(test_img_input))\n",
    "        prediction = np.squeeze(use_model.predict(test_img_input))\n",
    "\n",
    "        # convert softmax probabilities to integer values\n",
    "        predicted_img = np.argmax(prediction, axis=-1)\n",
    "\n",
    "        # convert integer encoding to rgb values\n",
    "        rgb_image = rgb_encode_mask(predicted_img)\n",
    "        rgb_ground_truth = rgb_encode_mask(ground_truth)\n",
    "\n",
    "        # visualize model predictions\n",
    "        display_images(\n",
    "            [test_img, rgb_ground_truth, rgb_image],\n",
    "            rows=1, titles=['Aerial', 'Ground Truth', 'Prediction']\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dir_images, use_model : Model = None):\n",
    "    if use_model is None:\n",
    "        model_dir = 'models/'\n",
    "        model_name = 'final_aerial_segmentation_20230507_192936400066.hdf5'\n",
    "        use_model = load_model(\n",
    "            model_dir + model_name,\n",
    "            custom_objects={'iou_coefficient': iou_coefficient, 'jaccard_index': jaccard_index})\n",
    "    \n",
    "    # print(use_model.summary())\n",
    "    # dir_images = sorted(dir_images,)\n",
    "    # predict images\n",
    "    predicted_imgs = []\n",
    "    for img_path in dir_images:\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        sample_images=[img]\n",
    "        display_images(sample_images, rows=1)\n",
    "\n",
    "        \n",
    "        img_original = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        sample_images=[img_original]\n",
    "        display_images(sample_images, rows=1)\n",
    "        \n",
    "        img_resized = cv2.resize(img_original, (160, 160))\n",
    "        sample_images=[img_resized]\n",
    "        display_images(sample_images, rows=1)\n",
    "\n",
    "        # img = img / 255\n",
    "        # sample_images=[img]\n",
    "        # display_images(sample_images, rows=1)\n",
    "\n",
    "        img = np.expand_dims(img_resized, axis=0)\n",
    "        sample_images=[img]\n",
    "        # display_images(sample_images, rows=1)\n",
    "\n",
    "        # img = np.expand_dims(img, axis=3)\n",
    "        img = img.astype(np.float32)\n",
    "        sample_images=[img]\n",
    "        # display_images(sample_images, rows=1)\n",
    "        \n",
    "        # make prediction with model and remove extra dimension\n",
    "        # prediction = np.squeeze(model.predict(test_img_input))\n",
    "        prediction = np.squeeze(use_model.predict(img))\n",
    "        sample_images=[prediction]\n",
    "        # display_images(sample_images, rows=1)\n",
    "\n",
    "        predicted_imgs.append(prediction)\n",
    "\n",
    "        # convert softmax probabilities to integer values\n",
    "        predicted_img = np.argmax(prediction, axis=-1)\n",
    "        print(predicted_img.shape)\n",
    "        sample_images=[predicted_img]\n",
    "        display_images(sample_images, rows=1)\n",
    "\n",
    "        # convert integer encoding to rgb values\n",
    "        rgb_image = rgb_encode_mask(predicted_img)\n",
    "        sample_images=[rgb_image]\n",
    "        display_images(sample_images, rows=1)\n",
    "\n",
    "        # visualize model predictions\n",
    "        display_images(\n",
    "            [img_resized, rgb_image],\n",
    "            rows=1, titles=['Aerial', 'Prediction']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = [r\"D:\\source\\20230507_TCC\\dataset\\20161112_sample_01\\DJI_0140.JPG\"]\n",
    "model_dir = 'models/'\n",
    "model_name = r\"final_aerial_segmentation_2022-11-09 22_37_27_640199.hdf5\"\n",
    "use_model = load_model(\n",
    "    model_dir + model_name,\n",
    "    custom_objects={'iou_coefficient': iou_coefficient, 'jaccard_index': jaccard_index})\n",
    "predict(dir_images, use_model)\n",
    "\n",
    "model_name = r\"final_aerial_segmentation_20230507_192936400066.hdf5\"\n",
    "use_model = load_model(\n",
    "    model_dir + model_name,\n",
    "    custom_objects={'iou_coefficient': iou_coefficient, 'jaccard_index': jaccard_index})\n",
    "predict(dir_images, use_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_u-net-aerial-imagery-segmentation_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
